{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import optimizers\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from sklearn.cluster import KMeans\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics.cluster import completeness_score\n",
    "from sklearn.metrics.cluster import v_measure_score\n",
    "from sklearn.metrics.cluster import homogeneity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import mnist_reader\n",
    "X_train, y_train = mnist_reader.load_mnist('dataset', kind='train')\n",
    "X_test, y_test = mnist_reader.load_mnist('dataset', kind='t10k')\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/michael/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/michael/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 2144.7275 - val_loss: 1189.4492\n",
      "Epoch 2/200\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 1019.5786 - val_loss: 913.7058\n",
      "Epoch 3/200\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 848.0335 - val_loss: 800.7558\n",
      "Epoch 4/200\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 765.6690 - val_loss: 738.4910\n",
      "Epoch 5/200\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 713.6741 - val_loss: 697.2805\n",
      "Epoch 6/200\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 678.6415 - val_loss: 679.0329\n",
      "Epoch 7/200\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 652.7493 - val_loss: 649.4215\n",
      "Epoch 8/200\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 633.6811 - val_loss: 627.6958\n",
      "Epoch 9/200\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 618.7314 - val_loss: 613.8641\n",
      "Epoch 10/200\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 606.5578 - val_loss: 607.1934\n",
      "Epoch 11/200\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 596.6996 - val_loss: 597.1363\n",
      "Epoch 12/200\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 588.2969 - val_loss: 588.2575\n",
      "Epoch 13/200\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 581.4670 - val_loss: 585.8804\n",
      "Epoch 14/200\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 576.1037 - val_loss: 576.4742\n",
      "Epoch 15/200\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 569.3268 - val_loss: 572.1266\n",
      "Epoch 16/200\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 565.1235 - val_loss: 567.5734\n",
      "Epoch 17/200\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 560.4802 - val_loss: 563.9435\n",
      "Epoch 18/200\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 556.1064 - val_loss: 558.6284\n",
      "Epoch 19/200\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 552.6625 - val_loss: 558.0403\n",
      "Epoch 20/200\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 548.7166 - val_loss: 552.3495\n",
      "Epoch 21/200\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 545.7829 - val_loss: 558.7060\n",
      "Epoch 22/200\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 541.8547 - val_loss: 546.3906\n",
      "Epoch 23/200\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 538.9961 - val_loss: 541.7777\n",
      "Epoch 24/200\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 536.8065 - val_loss: 541.8762\n",
      "Epoch 25/200\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 533.8063 - val_loss: 540.5906\n",
      "Epoch 26/200\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 530.8895 - val_loss: 535.3342\n",
      "Epoch 27/200\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 529.1154 - val_loss: 533.6148\n",
      "Epoch 28/200\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 527.1725 - val_loss: 534.9868\n",
      "Epoch 29/200\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 525.0296 - val_loss: 528.7580\n",
      "Epoch 30/200\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 522.7497 - val_loss: 531.6988\n",
      "Epoch 31/200\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 521.6288 - val_loss: 527.5143\n",
      "Epoch 32/200\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 518.3821 - val_loss: 524.9413\n",
      "Epoch 33/200\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 517.1672 - val_loss: 522.7595\n",
      "Epoch 34/200\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 515.5380 - val_loss: 524.8207\n",
      "Epoch 35/200\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 514.0208 - val_loss: 518.0593\n",
      "Epoch 36/200\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 512.4810 - val_loss: 516.9676\n",
      "Epoch 37/200\n",
      "60000/60000 [==============================] - 7s 108us/step - loss: 510.2816 - val_loss: 519.2060\n",
      "Epoch 38/200\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 509.4831 - val_loss: 524.3104\n",
      "Epoch 39/200\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 507.9281 - val_loss: 514.7605\n",
      "Epoch 40/200\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 506.7651 - val_loss: 512.3254\n",
      "Epoch 41/200\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 505.4456 - val_loss: 517.3378\n",
      "Epoch 42/200\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 504.2907 - val_loss: 511.5916\n",
      "Epoch 43/200\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 502.8535 - val_loss: 508.6868\n",
      "Epoch 44/200\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 502.4175 - val_loss: 512.2776\n",
      "Epoch 45/200\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 500.3934 - val_loss: 509.2563\n",
      "Epoch 46/200\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 499.0491 - val_loss: 509.1065\n",
      "Epoch 47/200\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 498.3825 - val_loss: 506.1295\n",
      "Epoch 48/200\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 498.1071 - val_loss: 504.9923\n",
      "Epoch 49/200\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 496.5361 - val_loss: 504.5676\n",
      "Epoch 50/200\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 495.2469 - val_loss: 504.5687\n",
      "Epoch 51/200\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 494.7159 - val_loss: 504.0536\n",
      "Epoch 52/200\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 494.5666 - val_loss: 499.6869\n",
      "Epoch 53/200\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 492.1939 - val_loss: 501.5123\n",
      "Epoch 54/200\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 491.6947 - val_loss: 501.7532\n",
      "Epoch 55/200\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 491.3204 - val_loss: 499.7708\n",
      "Epoch 56/200\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 490.4251 - val_loss: 502.2379\n",
      "Epoch 57/200\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 489.2266 - val_loss: 496.7969\n",
      "Epoch 58/200\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 489.1690 - val_loss: 495.8680\n",
      "Epoch 59/200\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 487.8119 - val_loss: 507.9065\n",
      "Epoch 60/200\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 487.9564 - val_loss: 497.8006\n",
      "Epoch 61/200\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 486.4342 - val_loss: 495.7430\n",
      "Epoch 62/200\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 487.2239 - val_loss: 497.0167\n",
      "Epoch 63/200\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 484.8932 - val_loss: 495.9814\n",
      "Epoch 64/200\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 484.3954 - val_loss: 494.5714\n",
      "Epoch 65/200\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 483.9428 - val_loss: 494.2353\n",
      "Epoch 66/200\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 483.9932 - val_loss: 494.4809\n",
      "Epoch 67/200\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 483.7488 - val_loss: 490.8891\n",
      "Epoch 68/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 7s 112us/step - loss: 482.2758 - val_loss: 492.9614\n",
      "Epoch 69/200\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 481.9346 - val_loss: 492.3455\n",
      "Epoch 70/200\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 480.9289 - val_loss: 488.6915\n",
      "Epoch 71/200\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 481.2281 - val_loss: 489.8379\n",
      "Epoch 72/200\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 480.5651 - val_loss: 489.9524\n",
      "Epoch 73/200\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 479.5284 - val_loss: 487.4817\n",
      "Epoch 74/200\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 479.2683 - val_loss: 489.1027\n",
      "Epoch 75/200\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 479.0499 - val_loss: 487.7068\n",
      "Epoch 76/200\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 479.1342 - val_loss: 487.9593\n",
      "Epoch 77/200\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 477.6189 - val_loss: 488.6067\n",
      "Epoch 78/200\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 477.5970 - val_loss: 485.2125\n",
      "Epoch 79/200\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 477.2065 - val_loss: 488.4354\n",
      "Epoch 80/200\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 476.9724 - val_loss: 488.2175\n",
      "Epoch 81/200\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 476.2697 - val_loss: 487.4519\n",
      "Epoch 82/200\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 476.0763 - val_loss: 484.9674\n",
      "Epoch 83/200\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 476.2792 - val_loss: 483.5691\n",
      "Epoch 84/200\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 474.6956 - val_loss: 485.6762\n",
      "Epoch 85/200\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 475.0542 - val_loss: 485.0242\n",
      "Epoch 86/200\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 474.3056 - val_loss: 484.6874\n",
      "Epoch 87/200\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 474.4203 - val_loss: 484.9334\n",
      "Epoch 88/200\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 473.4760 - val_loss: 488.2292\n",
      "Epoch 89/200\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 473.5643 - val_loss: 484.5284\n",
      "Epoch 90/200\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 473.4117 - val_loss: 484.1272\n",
      "Epoch 91/200\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 472.5349 - val_loss: 484.7683\n",
      "Epoch 92/200\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 472.4782 - val_loss: 484.7383\n",
      "Epoch 93/200\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 471.7962 - val_loss: 484.7044\n",
      "Epoch 94/200\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 471.9283 - val_loss: 480.8053\n",
      "Epoch 95/200\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 471.0997 - val_loss: 482.9014\n",
      "Epoch 96/200\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 471.5562 - val_loss: 480.2043\n",
      "Epoch 97/200\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 470.8629 - val_loss: 480.6983\n",
      "Epoch 98/200\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 469.9865 - val_loss: 480.6132\n",
      "Epoch 99/200\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 470.9651 - val_loss: 483.4282\n",
      "Epoch 100/200\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 469.4366 - val_loss: 480.8275\n",
      "Epoch 101/200\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 469.7427 - val_loss: 482.3325\n",
      "Epoch 102/200\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 469.7143 - val_loss: 481.4919\n",
      "Epoch 103/200\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 469.0966 - val_loss: 479.5644\n",
      "Epoch 104/200\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 468.5645 - val_loss: 478.9698\n",
      "Epoch 105/200\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 469.0380 - val_loss: 479.5345\n",
      "Epoch 106/200\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 467.9684 - val_loss: 478.5060\n",
      "Epoch 107/200\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 467.8404 - val_loss: 481.0492\n",
      "Epoch 108/200\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 467.6887 - val_loss: 476.1866\n",
      "Epoch 109/200\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 467.9007 - val_loss: 479.1802\n",
      "Epoch 110/200\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 467.4649 - val_loss: 478.6267\n",
      "Epoch 111/200\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 466.5815 - val_loss: 477.3982\n",
      "Epoch 112/200\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 467.1966 - val_loss: 479.3870\n",
      "Epoch 113/200\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 466.2068 - val_loss: 479.4612\n",
      "Epoch 114/200\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 466.6766 - val_loss: 481.7427\n",
      "Epoch 115/200\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 466.4890 - val_loss: 477.7899\n",
      "Epoch 116/200\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 465.6300 - val_loss: 477.0440\n",
      "Epoch 117/200\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 465.5551 - val_loss: 475.6485\n",
      "Epoch 118/200\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 465.3203 - val_loss: 475.3909\n",
      "Epoch 119/200\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 465.2323 - val_loss: 476.7462\n",
      "Epoch 120/200\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 464.8860 - val_loss: 474.2909\n",
      "Epoch 121/200\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 464.4360 - val_loss: 479.3123\n",
      "Epoch 122/200\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 464.8829 - val_loss: 479.5046\n",
      "Epoch 123/200\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 464.2972 - val_loss: 476.5664\n",
      "Epoch 124/200\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 463.8096 - val_loss: 478.5666\n",
      "Epoch 125/200\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 464.0740 - val_loss: 474.4003\n",
      "Epoch 126/200\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 463.3505 - val_loss: 474.2433\n",
      "Epoch 127/200\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 463.7297 - val_loss: 474.2330\n",
      "Epoch 128/200\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 462.7773 - val_loss: 479.3757\n",
      "Epoch 129/200\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 463.0878 - val_loss: 473.5324\n",
      "Epoch 130/200\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 463.2646 - val_loss: 473.7059\n",
      "Epoch 131/200\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 462.6656 - val_loss: 473.4521\n",
      "Epoch 132/200\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 462.2867 - val_loss: 473.3501\n",
      "Epoch 133/200\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 462.3912 - val_loss: 472.0995\n",
      "Epoch 134/200\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 462.3612 - val_loss: 477.5001\n",
      "Epoch 135/200\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 462.0382 - val_loss: 472.7914\n",
      "Epoch 136/200\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 461.5317 - val_loss: 474.0546\n",
      "Epoch 137/200\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 461.4961 - val_loss: 476.0083\n",
      "Epoch 138/200\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 461.1399 - val_loss: 471.5796\n",
      "Epoch 139/200\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 461.1795 - val_loss: 473.5305\n",
      "Epoch 140/200\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 461.2412 - val_loss: 473.4975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/200\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 460.3438 - val_loss: 471.1568\n",
      "Epoch 142/200\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 461.0957 - val_loss: 473.0326\n",
      "Epoch 143/200\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 460.3605 - val_loss: 476.2973\n",
      "Epoch 144/200\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 460.2808 - val_loss: 472.0424\n",
      "Epoch 145/200\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 459.9585 - val_loss: 472.7189\n",
      "Epoch 146/200\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 460.1981 - val_loss: 475.1881\n",
      "Epoch 147/200\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 460.0089 - val_loss: 474.2433\n",
      "Epoch 148/200\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 459.6001 - val_loss: 472.0339\n",
      "Epoch 149/200\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 459.5062 - val_loss: 470.9568\n",
      "Epoch 150/200\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 459.7704 - val_loss: 471.7520\n",
      "Epoch 151/200\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 458.8630 - val_loss: 471.5804\n",
      "Epoch 152/200\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 458.7617 - val_loss: 474.9181\n",
      "Epoch 153/200\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 458.7347 - val_loss: 471.5021\n",
      "Epoch 154/200\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 458.6549 - val_loss: 470.0289\n",
      "Epoch 155/200\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 458.8384 - val_loss: 467.3255\n",
      "Epoch 156/200\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 458.1962 - val_loss: 469.8782\n",
      "Epoch 157/200\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 458.6391 - val_loss: 469.7782\n",
      "Epoch 158/200\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 457.8759 - val_loss: 469.2956\n",
      "Epoch 159/200\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 458.0048 - val_loss: 469.7544\n",
      "Epoch 160/200\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 458.2327 - val_loss: 469.9547\n",
      "Epoch 161/200\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 458.5509 - val_loss: 468.7870\n",
      "Epoch 162/200\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 457.2338 - val_loss: 470.0516\n",
      "Epoch 163/200\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 457.6774 - val_loss: 472.3918\n",
      "Epoch 164/200\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 457.3153 - val_loss: 468.8310\n",
      "Epoch 165/200\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 456.9130 - val_loss: 468.0987\n",
      "Epoch 166/200\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 457.1725 - val_loss: 472.0406\n",
      "Epoch 167/200\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 456.9902 - val_loss: 469.4859\n",
      "Epoch 168/200\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 456.5606 - val_loss: 466.9016\n",
      "Epoch 169/200\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 456.9270 - val_loss: 467.5985\n",
      "Epoch 170/200\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 456.2021 - val_loss: 469.3983\n",
      "Epoch 171/200\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 456.9074 - val_loss: 467.2056\n",
      "Epoch 172/200\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 455.9347 - val_loss: 467.1839\n",
      "Epoch 173/200\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 456.3698 - val_loss: 468.4663\n",
      "Epoch 174/200\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 456.3661 - val_loss: 468.6474\n",
      "Epoch 175/200\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 456.1585 - val_loss: 467.3259\n",
      "Epoch 176/200\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 455.2564 - val_loss: 466.1702\n",
      "Epoch 177/200\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 455.7693 - val_loss: 471.2994\n",
      "Epoch 178/200\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 455.9145 - val_loss: 467.0024\n",
      "Epoch 179/200\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 455.9083 - val_loss: 467.4897\n",
      "Epoch 180/200\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 455.5474 - val_loss: 465.5558\n",
      "Epoch 181/200\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 454.8323 - val_loss: 466.2662\n",
      "Epoch 182/200\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 455.2633 - val_loss: 467.7284\n",
      "Epoch 183/200\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 454.8425 - val_loss: 466.1995\n",
      "Epoch 184/200\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 454.7113 - val_loss: 467.2809\n",
      "Epoch 185/200\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 454.9923 - val_loss: 466.4200\n",
      "Epoch 186/200\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 454.8540 - val_loss: 466.0619\n",
      "Epoch 187/200\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 453.8711 - val_loss: 463.6273\n",
      "Epoch 188/200\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 454.1879 - val_loss: 464.8928\n",
      "Epoch 189/200\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 454.1833 - val_loss: 465.1012\n",
      "Epoch 190/200\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 453.5733 - val_loss: 465.2476\n",
      "Epoch 191/200\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 454.4878 - val_loss: 465.9879\n",
      "Epoch 192/200\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 453.7829 - val_loss: 468.7705\n",
      "Epoch 193/200\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 453.8122 - val_loss: 481.5824\n",
      "Epoch 194/200\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 453.4626 - val_loss: 464.3775\n",
      "Epoch 195/200\n",
      "60000/60000 [==============================] - 8s 142us/step - loss: 453.5764 - val_loss: 467.4920\n",
      "Epoch 196/200\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 453.2136 - val_loss: 467.5971\n",
      "Epoch 197/200\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 453.0527 - val_loss: 469.2882\n",
      "Epoch 198/200\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 453.2399 - val_loss: 466.5100\n",
      "Epoch 199/200\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 453.2374 - val_loss: 463.8816\n",
      "Epoch 200/200\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 453.1639 - val_loss: 463.5371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2b3002b1d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch = 200\n",
    "batch_size = 256\n",
    "\n",
    "# this is the size of our encoded representations\n",
    "encoding_dim = 64\n",
    "hidden_dim = 256\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(hidden_dim, activation='relu')(input_img)\n",
    "\n",
    "encoded = Dense(encoding_dim, activation='linear')(encoded)\n",
    "\n",
    "decoded = Dense(hidden_dim, activation='relu')(encoded)\n",
    "decoded = Dense(784, activation='linear')(decoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=epoch,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "encoder = Model(input_img, encoded)\n",
    "encoded_images = encoder.predict(X_train)\n",
    "df = pd.DataFrame(encoded_images)\n",
    "df.to_csv(\"encoded_images.csv\")\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n = 10  # how many digits we will display\\nplt.figure(figsize=(20, 4))\\nfor i in range(10):\\n    # display original\\n    print(original_images[i].shape)\\n    ax = plt.subplot(2, n, i + 1)\\n    plt.imshow([original_images[i]].reshape(64, 64))\\n    plt.gray()\\n    ax.get_xaxis().set_visible(False)\\n    ax.get_yaxis().set_visible(False)\\n\\n    # display reconstruction\\n    ax = plt.subplot(2, n, i + 1 + n)\\n    plt.imshow([decoded_images[i]].reshape(28, 28))\\n    plt.gray()\\n    ax.get_xaxis().set_visible(False)\\n    ax.get_yaxis().set_visible(False)\\nplt.show()'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = [2, 17, 6, 4, 20, 9, 19, 7, 24, 1]\n",
    "index = [ind-1 for ind in index]\n",
    "decoded_images = autoencoder.predict(X_train[index])\n",
    "original_images = X_train[index]\n",
    "\n",
    "df = pd.DataFrame(decoded_images)\n",
    "df.to_csv(\"decoded_images.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "X_train_encoded = []\n",
    "with open('encoded_images.csv') as csvDataFile:\n",
    "    csvReader = csv.reader(csvDataFile)\n",
    "    for i,row in enumerate(csvReader):\n",
    "        if (i!=0):\n",
    "            row = [float(n) for n in row]\n",
    "            X_train_encoded.append(row)\n",
    "\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=10, random_state=0)\n",
    "kmeans.fit(X_train_encoded)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002453724877533153\n",
      "-2.4306742112943177e-05\n",
      "0.00024537370568253775\n",
      "0.0002453724877502927\n",
      "0.0002453712698301382\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(normalized_mutual_info_score(kmeans.labels_,y_train))\n",
    "print(adjusted_rand_score(kmeans.labels_, y_train))\n",
    "print(homogeneity_score(kmeans.labels_,y_train))\n",
    "print(v_measure_score(kmeans.labels_,y_train))\n",
    "print(completeness_score(kmeans.labels_,y_train))\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
